<!-- The (first) h1 will be used as the <title> of the HTML page -->
# Diego Allen

<!-- The unordered list immediately after the h1 will be formatted on a single
line. It is intended to be used for contact details -->
- <diegoallen@gmail.com>
- +(595) 981-448-131
- [LinkedIn](https://www.linkedin.com/in/dalleng/)
- [Github](https://github.com/dalleng)

<!-- The paragraph after the h1 and ul and before the first h2 is optional. It
is intended to be used for a short summary. -->
<!-- CEO and Software Engineer with knowledge of applied information theory,
including optimizing lossless compression schema of both the length-limited and
adaptive variants. -->

## Experience

<!-- You have to wrap the "left" and "right" half of these headings in spans by
hand -->
### <span>Senior Software Engineeer, [Routable Inc.](https://routable.com)</span> <span>Sept 2021 -- Present</span>

Routable is a platform that allows its users to send and receive business-to-business payments.

 
- Developed a global tax compliance system for B2B payments, enabling collection of W-9, W-8BEN, and W-8BEN-E forms from vendors during onboarding and allowing customers to request forms from existing vendors; created a dashboard for monitoring vendor tax information status.
 - Developed the [Quickswitch](https://web.archive.org/web/20230924163637/https://docs.routable.com/en/articles/5830914-switching-between-routable-accounts) feature enabling seamless toggling between multiple accounts without having to re-authenticate.
 - Worked on a project to introduce [client workspace URLs](https://web.archive.org/web/20231002223642/https://docs.routable.com/en/articles/6313469-customizing-your-workspace-name-and-url). E.g: client.app.com. Making it easier for customers with multiple accounts, for example, accounting firms, to have multiple sessions in parallel. Migrated 100% of customers from the generic top level domain to their custom subdomains seamlessly without re-authentication.
#### Technical Environment
Python, Django, Django REST Framework, PostgreSQL, Celery, Redis, React, Redux. 

### <span>Software Engineer, [Paladin](https://www.joinpaladin.com/)</span> <span>Jun 2017 -- Aug 2021</span>

Paladin is a Pro Bono management SaaS. The platform allows companies and law firms to track their pro bono work and legal service organizations to recruit volunteers.

-  Worked alongside the CTO in the early days to design the system. As the team grew, responsibilities expanded to writing and reviewing technical specs and doing code reviews on fellow engineers’ work.
- Implemented Single Sign On and Single Logout in the backend connecting with third-party Identity Providers via the SAML Protocol. This feature enabled the sales team to target larger enterprise customers.
- Built search feature that allowed users to search for Pro Bono opportunities by title, description and location increasing engagement by lawyers browsing for opportunities. Used PostrgreSQL's full text search functionality.
- Added end to end testing to the CI pipeline to ensure the proper behavior of core workflows inside the app and catch regressions. Used Docker and docker-compose to recreate the backend environment and to run the e2e test runner.

#### Technical Environment
Python, Django, PostgreSQL, Celery, React, Material UI, GraphQL, Heroku, AWS S3, Docker, CircleCI.

### <span>Software Engineer, Canopy via [Toptal](https://www.toptal.com/)</span> <span>Feb 2017 - Mar 2018</span>

Built the backend for the MVP of an iOS application to help freelancers find better jobs.

- Built scrapers to scrape jobs from major freelancing sites using Python and the Scrapy framework. Scraped 200,000+ jobs a week.
- Built REST API that handled user registration, login, logout and fed data to the mobile app using Python, Django and Django Rest Framework.
- Built async background tasks in the backend to score jobs for individual users and present the highest scored ones. Used Python, Django and Celery.
#### Technical Environment
Python, Django, PostgreSQL, Celery, Scrapy.

### <span>Software Engineer, [Scrapinghub](https://scrapinghub.com/)</span> <span>Dec 2015 - Aug 2016</span>

Cloud based web scraping service. Professional Services in web scraping.

- Worked on the Professional Services team working on web scraping spiders for customers using Python and the Scrapy Framework.
- Contributed to projects for the Data Services team, building web scraping spiders that crawled 1M+ pages, usually popular sites whose datasets were regularly asked for by clients (social networks, classifieds sites, etc.).

#### Technical Environment
Python, Django, Celery, Scrapy.

## Education

### <span>Catholic University “Nuestra Señora de la Asunción”; Asunción, Paraguay</span> <span>2008 -- 2014</span>
BSc. Computer Science